# Advanced Usage

Cellineã®é«˜åº¦ãªæ©Ÿèƒ½ã¨ä½¿ç”¨æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚
ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã€çµ±åˆè§£æãªã©ã€ä¸Šç´šè€…å‘ã‘ã®æ©Ÿèƒ½ã‚’è©³ã—ãè§£èª¬ã—ã¾ã™ã€‚

## ğŸš€ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†

### ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ç’°å¢ƒã§ã®å®Ÿè¡Œ

#### PBS/Torqueã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼

```bash
# PBSã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š
celline config --system PBS --pbs-server my-cluster

# ã‚¸ãƒ§ãƒ–ãƒªã‚½ãƒ¼ã‚¹ã®è¨­å®š
cat > pbs_config.toml << EOF
[pbs]
queue = "normal"
walltime = "48:00:00"
memory = "128GB"
ncpus = 32
nodes = 1
EOF

# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‡¦ç†
celline run count --config pbs_config.toml
```

#### Slurmã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼ˆã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…ï¼‰

```bash
#!/bin/bash
#SBATCH --job-name=celline-analysis
#SBATCH --time=24:00:00
#SBATCH --mem=64G
#SBATCH --cpus-per-task=16

module load R/4.3.0 cellranger/7.0.0

# ä¸¦åˆ—å‡¦ç†ã§è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã‚’å‡¦ç†
celline run download --nthread 16
celline run count --nthread 16
```

### ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªå‡¦ç†

```python
# å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ¡ãƒ¢ãƒªç®¡ç†
from celline import Project
from celline.utils.memory import MemoryManager

project = Project("./large-dataset")

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶é™
with MemoryManager(max_memory="32GB") as mem:
    # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«å‡¦ç†
    for chunk in project.iter_samples(chunk_size=10):
        project.process_chunk(chunk)
        mem.clear_cache()
```

## ğŸ”¬ ã‚«ã‚¹ã‚¿ãƒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­è¨ˆ

```python
from celline import Project, Pipeline
from celline.functions import *

# ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®šç¾©
class CustomSingleCellPipeline(Pipeline):
    def __init__(self, project: Project):
        super().__init__(project)
        
    def run(self):
        # æ®µéšçš„ãªå‡¦ç†
        self.stage1_data_acquisition()
        self.stage2_quality_control()
        self.stage3_analysis()
        self.stage4_integration()
    
    def stage1_data_acquisition(self):
        """ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ãƒ†ãƒ¼ã‚¸"""
        self.project.call(Add(self.sample_list))
        self.project.call(Download())
        
    def stage2_quality_control(self):
        """å“è³ªç®¡ç†ã‚¹ãƒ†ãƒ¼ã‚¸"""
        self.project.call(Count())
        self.project.call(Preprocess())
        
    def stage3_analysis(self):
        """è§£æã‚¹ãƒ†ãƒ¼ã‚¸"""
        self.project.call(PredictCelltype())
        self.project.call(Reduce())
        
    def stage4_integration(self):
        """çµ±åˆã‚¹ãƒ†ãƒ¼ã‚¸"""
        self.project.call(Integrate())

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ
project = Project("./my-analysis")
pipeline = CustomSingleCellPipeline(project)
pipeline.run()
```

### æ¡ä»¶åˆ†å²å‡¦ç†

```python
from celline.functions import *

project = Project("./conditional-analysis")

# æ¡ä»¶ã«åŸºã¥ãå‡¦ç†åˆ†å²
project.call_if_else(
    condition=lambda p: p.has_spatial_data(),
    true=SpatialAnalysis(),
    false=StandardAnalysis()
)

# ãƒ‡ãƒ¼ã‚¿å‹ã«åŸºã¥ãå‡¦ç†
if project.is_10x_data():
    project.call(Count())
elif project.is_smartseq_data():
    project.call(SmartSeqProcessing())
else:
    project.call(CustomProcessing())
```

## ğŸ“Š ãƒãƒƒãƒå‡¦ç†ã¨è‡ªå‹•åŒ–

### è¤‡æ•°ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€æ‹¬å‡¦ç†

```bash
#!/bin/bash
# batch_analysis.sh

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
PROJECTS="project_list.txt"

while IFS=',' read -r project_name gse_id description; do
    echo "Processing $project_name ($gse_id)"
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    mkdir -p "$project_name"
    cd "$project_name"
    
    # è§£æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    celline init "$project_name"
    celline run add "$gse_id"
    celline run download --nthread 8
    celline run count
    celline run preprocess
    celline run predict_celltype
    
    # çµæœã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
    tar -czf "../${project_name}_results.tar.gz" results/
    
    cd ..
done < "$PROJECTS"
```

### Makefileã‚’ä½¿ç”¨ã—ãŸè‡ªå‹•åŒ–

```makefile
# Makefile for Celline analysis

# å¤‰æ•°å®šç¾©
PROJECT_NAME := my-scrna-analysis
GSE_ID := GSE123456
NTHREAD := 8

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
all: init download count preprocess analyze

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
init:
	celline init $(PROJECT_NAME)

# ã‚µãƒ³ãƒ—ãƒ«è¿½åŠ 
add:
	celline run add $(GSE_ID)

# ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
download: add
	celline run download --nthread $(NTHREAD)

# ã‚«ã‚¦ãƒ³ãƒˆå‡¦ç†
count: download
	celline run count

# å‰å‡¦ç†
preprocess: count
	celline run preprocess

# è§£æ
analyze: preprocess
	celline run predict_celltype
	celline run reduce
	celline run integrate

# çµæœã®ç¢ºèª
check:
	celline info
	find results/ -name "*.csv" -o -name "*.png" | head -10

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
clean:
	rm -rf resources/*/raw resources/*/tmp
	
# å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
distclean:
	rm -rf resources/ data/ results/

.PHONY: all init add download count preprocess analyze check clean distclean
```

## ğŸ”„ çµ±åˆè§£æ

### è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆ

```python
from celline.functions.integrate import MultiDatasetIntegration

# è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆè§£æ
integration = MultiDatasetIntegration([
    "dataset1_GSE123456",
    "dataset2_GSE789012", 
    "dataset3_GSE345678"
])

project = Project("./integrated-analysis")
project.call(integration)

# ãƒãƒƒãƒã‚¨ãƒ•ã‚§ã‚¯ãƒˆè£œæ­£æ‰‹æ³•ã®æ¯”è¼ƒ
methods = ["harmony", "combat", "mnn", "cca"]
for method in methods:
    integration.method = method
    project.call(integration)
    project.save_results(f"integration_{method}")
```

### ãƒ¡ã‚¿è§£æ

```python
from celline.functions.meta import MetaAnalysis

# ãƒ¡ã‚¿è§£æã®å®Ÿè¡Œ
meta = MetaAnalysis([
    {"gse": "GSE123456", "condition": "control", "tissue": "brain"},
    {"gse": "GSE789012", "condition": "disease", "tissue": "brain"},
    {"gse": "GSE345678", "condition": "treatment", "tissue": "brain"}
])

project = Project("./meta-analysis")
project.call(meta)

# çµæœã®çµ±è¨ˆè§£æ
meta.perform_differential_analysis()
meta.generate_forest_plots()
```

## ğŸ§¬ ã‚«ã‚¹ã‚¿ãƒ è§£ææ©Ÿèƒ½

### æ–°ã—ã„è§£æé–¢æ•°ã®ä½œæˆ

```python
from celline.functions._base import CellineFunction
import argparse

class CustomCellTypeClassification(CellineFunction):
    """ã‚«ã‚¹ã‚¿ãƒ ç´°èƒå‹åˆ†é¡é–¢æ•°"""
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.8):
        super().__init__()
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
    
    def call(self, project):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        import pickle
        import scanpy as sc
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        with open(self.model_path, 'rb') as f:
            model = pickle.load(f)
        
        # å„ã‚µãƒ³ãƒ—ãƒ«ã®å‡¦ç†
        for sample_id in project.get_samples():
            adata = project.load_sample_data(sample_id)
            
            # ç‰¹å¾´é‡ã®æŠ½å‡º
            features = self.extract_features(adata)
            
            # äºˆæ¸¬ã®å®Ÿè¡Œ
            predictions = model.predict(features)
            confidence = model.predict_proba(features)
            
            # ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            high_conf_mask = confidence.max(axis=1) >= self.confidence_threshold
            
            # çµæœã®ä¿å­˜
            adata.obs['custom_celltype'] = predictions
            adata.obs['celltype_confidence'] = confidence.max(axis=1)
            adata.obs['high_confidence'] = high_conf_mask
            
            project.save_sample_data(sample_id, adata)
        
        return project
    
    def extract_features(self, adata):
        """ç‰¹å¾´é‡æŠ½å‡º"""
        # ã‚«ã‚¹ã‚¿ãƒ ç‰¹å¾´é‡ã®è¨ˆç®—
        import numpy as np
        
        # é«˜å¯å¤‰éºä¼å­ã®ç™ºç¾
        hvg_expr = adata[:, adata.var.highly_variable].X.toarray()
        
        # ãƒ‘ã‚¹ã‚¦ã‚§ã‚¤ã‚¹ã‚³ã‚¢
        pathway_scores = self.calculate_pathway_scores(adata)
        
        # çµåˆ
        features = np.concatenate([hvg_expr, pathway_scores], axis=1)
        return features
    
    def add_cli_args(self, parser: argparse.ArgumentParser):
        """CLIå¼•æ•°ã®è¿½åŠ """
        parser.add_argument('--model-path', required=True,
                          help='Path to the trained classification model')
        parser.add_argument('--confidence-threshold', type=float, default=0.8,
                          help='Confidence threshold for predictions')
    
    def get_description(self):
        return "Custom cell type classification using trained models"
```

### è§£æé–¢æ•°ã®ç™»éŒ²

```python
# ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ã‚’Cellineã«ç™»éŒ²
from celline.cli.registry import get_registry

registry = get_registry()
registry.register_function(
    name="custom_classify",
    class_ref=CustomCellTypeClassification,
    module_path="my_custom_functions.classification"
)

# CLIçµŒç”±ã§ä½¿ç”¨
# celline run custom_classify --model-path my_model.pkl
```

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®é«˜åº¦ãªæ©Ÿèƒ½

### ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ

```python
from celline.visualization import CellinePlotter

class AdvancedVisualization(CellineFunction):
    def call(self, project):
        plotter = CellinePlotter(project)
        
        # è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®çµ±åˆUMAP
        plotter.integrated_umap(
            samples=project.get_samples(),
            color_by="celltype",
            split_by="condition"
        )
        
        # ç™ºç¾ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        plotter.expression_heatmap(
            genes=["CD4", "CD8A", "IL2", "IFNG"],
            group_by="celltype",
            save_path="results/expression_heatmap.pdf"
        )
        
        # è»Œè·¡è§£æ
        plotter.trajectory_plot(
            root_cell="stem_cell",
            save_path="results/trajectory.pdf"
        )
        
        return project
```

### ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–å¯è¦–åŒ–

```python
import plotly.graph_objects as go
from celline.interactive import InteractivePlotter

def create_interactive_plots(project):
    plotter = InteractivePlotter(project)
    
    # 3D UMAP
    fig = plotter.plot_3d_umap(
        color_by="celltype",
        hover_data=["sample", "condition", "batch"]
    )
    
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–éºä¼å­ç™ºç¾
    expr_fig = plotter.plot_gene_expression(
        genes=["CD4", "CD8A"],
        plot_type="violin"
    )
    
    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ä½œæˆ
    dashboard = plotter.create_dashboard([fig, expr_fig])
    dashboard.serve(port=8050)
```

## ğŸ”Œ APIçµ±åˆ

### å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æº

```python
from celline.database import ExternalDBConnector

class CustomDBIntegration(CellineFunction):
    def __init__(self, db_config: dict):
        self.db_config = db_config
    
    def call(self, project):
        # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’å–å¾—
        connector = ExternalDBConnector(self.db_config)
        
        for sample_id in project.get_samples():
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ‹¡å¼µ
            extended_meta = connector.fetch_extended_metadata(sample_id)
            
            # éºä¼å­ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®æ›´æ–°
            gene_annotations = connector.fetch_gene_annotations(
                species=project.get_species()
            )
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«çµ±åˆ
            project.update_sample_metadata(sample_id, extended_meta)
            project.update_gene_annotations(gene_annotations)
        
        return project
```

### æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

class MLPipeline(CellineFunction):
    def __init__(self, model_config: dict):
        self.model_config = model_config
    
    def call(self, project):
        # æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', RandomForestClassifier(**self.model_config))
        ])
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        X_train, y_train = project.prepare_training_data()
        
        # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        pipeline.fit(X_train, y_train)
        
        # äºˆæ¸¬ã®å®Ÿè¡Œ
        for sample_id in project.get_samples():
            X_test = project.prepare_test_data(sample_id)
            predictions = pipeline.predict(X_test)
            project.save_predictions(sample_id, predictions)
        
        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        project.save_model(pipeline, "trained_classifier.pkl")
        
        return project
```

## ğŸ”§ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ä¸¦åˆ—å‡¦ç†ã®æœ€é©åŒ–

```python
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from celline.utils import ProcessManager

class OptimizedProcessing(CellineFunction):
    def call(self, project):
        samples = project.get_samples()
        
        # CPUé›†ç´„çš„ã‚¿ã‚¹ã‚¯ã¯ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—
        with ProcessPoolExecutor(max_workers=8) as executor:
            cpu_futures = [
                executor.submit(self.cpu_intensive_task, sample)
                for sample in samples
            ]
        
        # I/Oé›†ç´„çš„ã‚¿ã‚¹ã‚¯ã¯ã‚¹ãƒ¬ãƒƒãƒ‰ä¸¦åˆ—
        with ThreadPoolExecutor(max_workers=16) as executor:
            io_futures = [
                executor.submit(self.io_intensive_task, sample)
                for sample in samples
            ]
        
        # çµæœã®åé›†
        cpu_results = [f.result() for f in cpu_futures]
        io_results = [f.result() for f in io_futures]
        
        return project
```

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æœ€é©åŒ–

```python
from celline.utils.memory import MemoryProfiler, LazyLoader

class MemoryOptimizedAnalysis(CellineFunction):
    def call(self, project):
        with MemoryProfiler() as profiler:
            # é…å»¶èª­ã¿è¾¼ã¿ã‚’ä½¿ç”¨
            lazy_data = LazyLoader(project.data_path)
            
            # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®å‡¦ç†
            for chunk in lazy_data.iter_chunks(chunk_size=1000):
                self.process_chunk(chunk)
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–
                if profiler.get_memory_usage() > profiler.memory_limit:
                    profiler.clear_cache()
                    gc.collect()
        
        return project
```

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å¾©æ—§

### å …ç‰¢ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
from celline.utils.exceptions import CellineException
from celline.utils.recovery import RecoveryManager

class RobustAnalysis(CellineFunction):
    def call(self, project):
        recovery = RecoveryManager(project)
        
        try:
            # åˆ†æã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œ
            for step in self.analysis_steps:
                checkpoint = recovery.create_checkpoint(step.name)
                
                try:
                    step.execute(project)
                    recovery.mark_success(checkpoint)
                except Exception as e:
                    recovery.mark_failure(checkpoint, e)
                    
                    # è‡ªå‹•å¾©æ—§ã®è©¦è¡Œ
                    if recovery.can_recover(step):
                        recovery.recover_from_checkpoint(checkpoint)
                    else:
                        raise CellineException(f"Step {step.name} failed: {e}")
        
        except CellineException as e:
            # è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
            recovery.generate_error_report(e)
            raise
        
        return project
```

---

::alert{type="warning"}
é«˜åº¦ãªæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹éš›ã¯ã€ååˆ†ãªãƒ†ã‚¹ãƒˆã‚’è¡Œã„ã€æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿè¡Œå‰ã«å°è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å‹•ä½œç¢ºèªã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
::